#  PACKFY CUBA - Configuraci贸n Logstash v4.0

input {
  # Logs de Django desde archivos
  file {
    path => "/var/log/packfy/django/*.log"
    start_position => "beginning"
    type => "django"
    codec => multiline {
      pattern => "^\d{4}-\d{2}-\d{2}"
      negate => true
      what => "previous"
    }
    tags => ["django", "backend"]
  }

  # Logs de Nginx
  file {
    path => "/var/log/nginx/access.log"
    start_position => "beginning"
    type => "nginx_access"
    tags => ["nginx", "access"]
  }

  file {
    path => "/var/log/nginx/error.log"
    start_position => "beginning"
    type => "nginx_error"
    tags => ["nginx", "error"]
  }

  # Logs de PostgreSQL
  file {
    path => "/var/log/postgresql/*.log"
    start_position => "beginning"
    type => "postgresql"
    tags => ["postgresql", "database"]
  }

  # Logs de Redis
  file {
    path => "/var/log/redis/*.log"
    start_position => "beginning"
    type => "redis"
    tags => ["redis", "cache"]
  }

  # Logs de Docker containers
  docker {
    host => "unix:///var/run/docker.sock"
    type => "docker"
    tags => ["docker", "container"]
  }

  # Logs v铆a TCP (para aplicaciones)
  tcp {
    port => 5000
    type => "tcp_input"
    codec => json_lines
    tags => ["tcp", "application"]
  }
}

filter {
  # === FILTROS PARA LOGS DE DJANGO ===
  if [type] == "django" {
    grok {
      match => {
        "message" => "%{TIMESTAMP_ISO8601:timestamp} \[%{LOGLEVEL:level}\] %{DATA:logger}: %{GREEDYDATA:message_content}"
      }
      overwrite => [ "message" ]
    }

    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss,SSS" ]
    }

    # Extraer informaci贸n espec铆fica de Django
    if [logger] =~ /django\.request/ {
      grok {
        match => {
          "message_content" => "%{WORD:method} %{URIPATH:path}(?:%{URIPARAM:params})? %{NUMBER:status:int} %{NUMBER:response_time:float}"
        }
      }
      mutate {
        add_tag => ["http_request"]
      }
    }

    if [logger] =~ /packfy\./ {
      mutate {
        add_tag => ["business_logic"]
      }
    }

    if [level] == "ERROR" or [level] == "CRITICAL" {
      mutate {
        add_tag => ["alert"]
      }
    }
  }

  # === FILTROS PARA LOGS DE NGINX ===
  if [type] == "nginx_access" {
    grok {
      match => {
        "message" => "%{NGINXACCESS}"
      }
    }

    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }

    mutate {
      convert => {
        "response" => "integer"
        "bytes" => "integer"
        "response_time" => "float"
      }
    }

    # Clasificar por c贸digos de respuesta
    if [response] >= 500 {
      mutate {
        add_tag => ["server_error"]
      }
    } else if [response] >= 400 {
      mutate {
        add_tag => ["client_error"]
      }
    }

    # Detectar bots y crawlers
    if [agent] =~ /bot|crawler|spider/i {
      mutate {
        add_tag => ["bot"]
      }
    }
  }

  if [type] == "nginx_error" {
    grok {
      match => {
        "message" => "%{DATESTAMP:timestamp} \[%{DATA:log_level}\] %{NUMBER:pid}#%{NUMBER:tid}: (?:\*%{NUMBER:connection_id} )?%{GREEDYDATA:error_message}"
      }
    }

    date {
      match => [ "timestamp", "yyyy/MM/dd HH:mm:ss" ]
    }

    mutate {
      add_tag => ["alert"]
    }
  }

  # === FILTROS PARA LOGS DE POSTGRESQL ===
  if [type] == "postgresql" {
    grok {
      match => {
        "message" => "%{DATESTAMP:timestamp} %{TZ:timezone} \[%{NUMBER:pid}\] %{WORD:level}: %{GREEDYDATA:message_content}"
      }
    }

    date {
      match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
    }

    # Detectar consultas lentas
    if [message_content] =~ /duration: [0-9]+\.[0-9]+ ms/ {
      grok {
        match => {
          "message_content" => "duration: %{NUMBER:query_duration:float} ms"
        }
      }

      if [query_duration] > 1000 {
        mutate {
          add_tag => ["slow_query"]
        }
      }
    }

    # Detectar errores de conexi贸n
    if [message_content] =~ /could not connect|connection refused|authentication failed/ {
      mutate {
        add_tag => ["connection_error", "alert"]
      }
    }
  }

  # === FILTROS PARA LOGS DE REDIS ===
  if [type] == "redis" {
    grok {
      match => {
        "message" => "%{NUMBER:pid}:%{WORD:role} %{DATESTAMP:timestamp} %{WORD:level} %{GREEDYDATA:message_content}"
      }
    }

    date {
      match => [ "timestamp", "dd MMM HH:mm:ss.SSS" ]
    }

    # Detectar problemas de memoria
    if [message_content] =~ /memory|oom|out of memory/i {
      mutate {
        add_tag => ["memory_issue", "alert"]
      }
    }
  }

  # === FILTROS PARA LOGS DE DOCKER ===
  if [type] == "docker" {
    # Extraer nombre del contenedor
    if [docker][name] {
      mutate {
        add_field => { "container_name" => "%{[docker][name]}" }
      }
    }

    # Clasificar por servicio
    if [container_name] =~ /backend/ {
      mutate {
        add_tag => ["backend_service"]
      }
    } else if [container_name] =~ /frontend/ {
      mutate {
        add_tag => ["frontend_service"]
      }
    } else if [container_name] =~ /postgres/ {
      mutate {
        add_tag => ["database_service"]
      }
    } else if [container_name] =~ /redis/ {
      mutate {
        add_tag => ["cache_service"]
      }
    }
  }

  # === FILTROS GLOBALES ===

  # Agregar informaci贸n de geolocalizaci贸n para IPs
  if [clientip] {
    geoip {
      source => "clientip"
      target => "geoip"
    }
  }

  # Enriquecer con informaci贸n del host
  mutate {
    add_field => {
      "environment" => "${ENVIRONMENT:development}"
      "service" => "packfy-cuba"
      "version" => "${APP_VERSION:unknown}"
    }
  }

  # Normalizar niveles de log
  translate {
    field => "level"
    destination => "log_severity"
    dictionary => {
      "DEBUG" => "debug"
      "INFO" => "info"
      "WARNING" => "warning"
      "ERROR" => "error"
      "CRITICAL" => "critical"
      "FATAL" => "critical"
    }
    fallback => "unknown"
  }

  # Calcular hash para deduplicaci贸n
  fingerprint {
    source => ["message", "logger", "level", "host"]
    target => "[@metadata][fingerprint]"
    method => "SHA1"
  }
}

output {
  # === OUTPUT A ELASTICSEARCH ===
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "packfy-logs-%{+YYYY.MM.dd}"
    template_name => "packfy-logs"
    template => "/usr/share/logstash/templates/packfy-logs.json"
    template_overwrite => true

    # Configuraci贸n de documento
    document_id => "%{[@metadata][fingerprint]}"

    # Configuraci贸n de rendimiento
    workers => 2
    flush_size => 500
    idle_flush_time => 5
  }

  # === OUTPUT CONDICIONALES ===

  # Alertas cr铆ticas a webhook
  if "alert" in [tags] and [log_severity] in ["error", "critical"] {
    http {
      url => "http://alertmanager:9093/api/v1/alerts"
      http_method => "post"
      format => "json"
      mapping => {
        "labels" => {
          "alertname" => "LogAlert"
          "severity" => "%{log_severity}"
          "service" => "%{service}"
          "environment" => "%{environment}"
          "host" => "%{host}"
        }
        "annotations" => {
          "summary" => "Error detectado en logs"
          "description" => "%{message}"
        }
        "generatorURL" => "http://kibana:5601"
      }
    }
  }

  # Logs de negocio a 铆ndice separado
  if "business_logic" in [tags] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "packfy-business-%{+YYYY.MM.dd}"
    }
  }

  # M茅tricas de performance a 铆ndice separado
  if [response_time] {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "packfy-performance-%{+YYYY.MM.dd}"
    }
  }

  # Debug output (solo en desarrollo)
  if "${ENVIRONMENT}" == "development" {
    stdout {
      codec => rubydebug
    }
  }
}
